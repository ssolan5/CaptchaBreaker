\section{Related Work}
\label{sec:related}

\textbf{Breaking audio captchas.} Tam et al.~\cite{tam2008improving} were the 
first to evaluate the robustness of audio captchas against automated attacks,
and reported a success rate of 58\% against audio captchas that contained 
digits and random speech segments as background noise. Subsequently, 
Burzstein and Bethard presented Decaptcha, a system that was able to solve 75\%
of eBay's audio captchas~\cite{Bursztein2009}. While they experimented with Sphynx,
which was at the time a state-of-the-art speech recognizer, they were only able to 
achieve a 1\% accuracy. On the other hand, our experiments reveal how speech recognition
technology has greatly evolved, allowing us to accurately solve audio challenges
across a large number of services.

Bursztein et al.~\cite{bursztein2011failure} conducted an extensive study on audio audio 
challenges that contained digits and letters and broke the Yahoo, Microsoft, and eBay 
captchas with approximate success rates of 45\%, 49\%, and 83\% respectively. However, 
their system was only able to solve $\sim1.5\%$ of \re challenges, due to the presence 
of semantic noise. More recently, Sano et al.~\cite{Sano2013} focused on the \re
version that contained semantic noise and implemented a custom solver that achieved the best
results up to that point, with a 52\% accuracy. Meutzner et al.~\cite{meutzner2014using} demonstrated 
an improvement over those results and reported a 63\% accuracy against the same version of \re. While
we experiment with the latest versions of \re, which have differences, 
we obtain significantly better results with a 83.9\%-98.3\& accuracy.

\textbf{Captchas and accessibility.} According to Shirali-Shahreza et al.~\cite{shirali2011accessibility},
three groups of people have trouble with visual challenges; the visually impaired,
with dyslexia, and users suffering from motor impairment diseases like Parkinson's.
Chellapilla et al.~\cite{Chellapilla} argued that Human-friendly Interaction Proofs (HIPs)
must approach a success rate of at least 90\%. They also argued that, due to their scale, automated attacks
should be able to solve a challenge in less than 0.01\% of their attempts, for a captcha system to be considered
robust. Sauer et al. conducted a usability study with six blind participants on Google's \re, 
and found that they were only able to solve 46\% of the audio challenges~\cite{sauer2008towards}.
They also found that the average amount of time taken to correctly solve an audio challenge was over 65 seconds.
This is significantly higher than the 28.4 seconds that users required for solving audio captchas
in the extensive user study conducted by Bursztein et al.~\cite{captchas-are-hard}.

While conducting a study with blind high school students, Bigham et al.~\cite{bigham2008inspiring}
found that when the students were presented with an audio captcha, none of them were able to solve the challenge 
and their sighted instructors ended up solving the visual version instead. In a subsequent
study conducted with 89 blind users~\cite{bigham2009evaluating}, they found that users achieved 
only a 43\% success rate when solving 10 popular audio captchas.
%In the same study \cite{bigham2009evaluating}, it was also found that screen readers used by blind users speak over
%playing captchas. As users navigate to the answer box, the accessibility software continue speaking the interface while
%talking over the playing audio challenge. A playing audio challenge does not pause for solvers as they type their answer
%and reviewing an audio captcha is cumbersome, often requiring the user to start again from the beginning. Also, replaying
%an audio captcha requires solvers to navigate away from the answer box in order to access the controls of the audio player.
%Thus, the authors proposed a system and optimized the interface of popular audio captcha services without altering the
%underlying implementation and found that the performance increased to 59\%. 

Holman et al.~\cite{holman2007developing} proposed the extension of image captchas to include related
sounds (e.g., an image challenge showing a train would be accompanied by an audio recording of a train), 
as an alternative type of challenge for blind users. An alternative design that required users to identify 
a series of sounds was later proposed~\cite{Lazar:2012}, and the authors conducted a user study in which the
participants achieved a success rate of over 90\%. Krol et al.~\cite{krol2016better} conducted a user study 
to explore a replacement to current captcha schemes but found that users were apprehensive due to the privacy 
concerns as well as an increased sense of frustration.

\textbf{Other applications of audio captchas.} Polakis et al.~\cite{polakis:syssec11} proposed the deployment of 
simple audio challenges (e.g., solving simple math equations, or spelling words with a traditional telephone keypad)
as a defense against automated attacks in telephony systems. Markkola and Lindqvist~\cite{markkola2008accessible}
proposed the deployment of audio captchas that contained digits for preventing telephone SPAM~\cite{sok-robocalls}.

\textbf{Google \re.} In a recent study, Sivakorn et al.~\cite{sivakorn:eurosp16} demonstrated how off-the-shelf 
deep learning systems could be employed for breaking Google's image-based \re system. They also presented a series 
of safeguards employed by \re for preventing automated attacks. Similarly, in our study we demonstrate how off-the-shelf 
speech recognition systems can be used for breaking a wide range of audio captcha systems, and identify a varying set
of safeguards across certain captcha services. Interestingly, our experiments demonstrate a significantly higher success rate,
underlining the importance of finding suitable alternatives for accessible captchas, as the availability of audio captchas 
exposes services to significant risks.

In an independent concurrent study Bock et al.~\cite{bock17uncaptcha} presented an attack against \re.
While their approach presents several similarities with our work, there are considerable differences. First of all,
their work focuses only on \re, whereas we conduct an extensive evaluation of the audio captcha ecosystem by analyzing
and attacking seven different captcha services and two versions of \re. As a result, their attack evaluation is limited to
numerical digits, whereas our attacks cover captcha schemes incorporating a wide range of dictionaries.
Furthermore, for their attack they break down each audio challenge into the separate digits,
submit all the digits to 5 online speech recognition services (and one offline solver), and then construct the solution based 
on the output of the various engines by considering the confidence scores assigned during their analysis.
This results in their attack having a significantly higher cost as multiple services are used for 
transcribing a single challenge. On the other hand we demonstrate an equally accurate attack (our attack against 
that version of \re is $\sim$1.2\% less accurate) while using a single speech recognition service, thus, incurring a much lower cost.
As our attacks leverage each speech recognition engine separately, we are able to identify the distinct patterns 
of mistakes in transcriptions per captcha scheme and speech recognition service during the post-processing.
Overall, while their study is an important contribution to the research community that demonstrates an effective attack and 
sheds light on this significant threat, our work presents a more comprehensive evaluation of the threat landscape while achieving
those results at a significantly lower cost.

%The problem statement that they approach is purely for numbers as audio captcha, whereas our attack focuses on alpha-numeric, NATO phonetic 
%spelling, phrases which are dictionary words as well (As said before we attack 8 other services). Like our attack they also apply mappings to improve 
%the efficiency of transcriptions received from each cloud service. They have added different categories for it whereas we lump them as one. They divide 
%them as exact-homophone and a near homophone. They describe an exact homophone as when the word transcribed by the audio service is describing how the 
%number sounds (for example “four” as “for” ) and a near homophone as a slightly erroneous but close enough transcription of the number (for example “six” 
%as “sex”).
%
%
%The attack method in the woot paper involves dividing the audio file into its constituent digit audio snippets and then sending those audio snippets 
%to multiple cloud based audio services which send back a number of different valid answers and then utilizing homophone predictions to accurately decide 
%which of those transcriptions are correct, then they assemble the digits from each service based upon a confidence score assigned as per their analysis.
%
%Our attack method is markedly different from theirs, Their method yields comparable accuracy value as our attack does, however they do not try to use 
%    the existing features in the cloud based speech recognition i.e different accents nor do they attack other captcha services utilizing this method. Their 
%    paper additionally covers offline speech recognition based on extracting features from the audio which our paper does not consider.
%
