\section{Related Work}
\label{sec:related}

\textbf{Breaking audio captchas.} Tam et al.~\cite{tam2008improving} were the 
first to evaluate the robustness of audio captchas against automated attacks,
and reported a success rate of 58\% against audio captchas that contained 
digits and random speech segments as background noise. Subsequently, 
Burzstein and Bethard presented Decaptcha, a system that was able to solve 75\%
of eBay's audio captchas~\cite{Bursztein2009}. While they experimented with Sphynx,
which was at the time a state-of-the-art speech recognizer, they were only able to 
achieve a 1\% accuracy. On the other hand, our experiments reveal how speech recognition
technology has greatly evolved, allowing us to accurately solve audio challenges
across a large number of services.

Bursztein et al.~\cite{bursztein2011failure} conducted an extensive study on audio audio 
challenges that contained digits and letters and broke the Yahoo, Microsoft, and eBay 
captchas with approximate success rates of 45\%, 49\%, and 83\% respectively. However, 
their system was only able to solve $\sim1.5\%$ of \re challenges, due to the presence 
of semantic noise. More recently, Sano et al.~\cite{Sano2013} focused on the \re
version that contained semantic noise and implemented a custom solver that achieved the best
results up to that point, with a 52\% accuracy. Meutzner et al.~\cite{meutzner2014using} demonstrated 
an improvement over those results and reported a 63\% accuracy against the same version of \re. While
we experiment with the latest versions of \re, which have differences, 
we obtain significantly better results with a 83.9\%-98.3\& accuracy.

\textbf{Captchas and accessibility.} According to Shirali-Shahreza et al.~\cite{shirali2011accessibility},
three groups of people have trouble with visual challenges; the visually impaired,
with dyslexia, and users suffering from motor impairment diseases like Parkinson's.
Chellapilla et al.~\cite{Chellapilla} argued that Human-friendly Interaction Proofs (HIPs)
must approach a success rate of at least 90\%. They also argued that, due to their scale, automated attacks
should be able to solve a challenge in less than 0.01\% of their attempts, for a captcha system to be considered
robust. Sauer et al. conducted a usability study with six blind participants on Google's \re, 
and found that they were only able to solve 46\% of the audio challenges~\cite{sauer2008towards}.
They also found that the average amount of time taken to correctly solve an audio challenge was over 65 seconds.
This is significantly higher than the 28.4 seconds that users required for solving audio captchas
in the extensive user study conducted by Bursztein et al.~\cite{captchas-are-hard}.

While conducting a study with blind high school students, Bigham et al.~\cite{bigham2008inspiring}
found that when the students were presented with an audio captcha, none of them were able to solve the challenge 
and their sighted instructors ended up solving the visual version instead. In a subsequent
study conducted with 89 blind users~\cite{bigham2009evaluating}, they found that users achieved 
only a 43\% success rate when solving 10 popular audio captchas.
%In the same study \cite{bigham2009evaluating}, it was also found that screen readers used by blind users speak over
%playing captchas. As users navigate to the answer box, the accessibility software continue speaking the interface while
%talking over the playing audio challenge. A playing audio challenge does not pause for solvers as they type their answer
%and reviewing an audio captcha is cumbersome, often requiring the user to start again from the beginning. Also, replaying
%an audio captcha requires solvers to navigate away from the answer box in order to access the controls of the audio player.
%Thus, the authors proposed a system and optimized the interface of popular audio captcha services without altering the
%underlying implementation and found that the performance increased to 59\%. 

Holman et al.~\cite{holman2007developing} proposed the extension of image captchas to include related
sounds (e.g., an image challenge showing a train would be accompanied by an audio recording of a train), 
as an alternative type of challenge for blind users. An alternative design that required users to identify 
a series of sounds was later proposed~\cite{Lazar:2012}, and the authors conducted a user study in which the
participants achieved a success rate of over 90\%. Krol et al.~\cite{krol2016better} conducted a user study 
to explore a replacement to current captcha schemes but found that users were apprehensive due to the privacy 
concerns as well as an increased sense of frustration.

\textbf{Other applications of audio captchas.} Polakis et al.~\cite{polakis:syssec11} proposed the deployment of 
simple audio challenges (e.g., solving simple math equations, or spelling words with a traditional telephone keypad)
as a defense against automated attacks in telephony systems. Markkola and Lindqvist~\cite{markkola2008accessible}
proposed the deployment of audio captchas that contained digits for preventing telephone SPAM~\cite{sok-robocalls}.

\textbf{Google \re.} In a recent study, Sivakorn et al.~\cite{sivakorn:eurosp16} demonstrated how off-the-shelf 
deep learning systems could be employed for breaking Google's image-based \re system. They also presented a series 
of safeguards employed by \re for preventing automated attacks. Similarly, in our study we demonstrate how off-the-shelf 
speech recognition systems can be used for breaking a wide range of audio captcha systems, and identify a varying set
of safeguards across certain captcha services. Interestingly, our experiments demonstrate a significantly higher success rate,
underlining the importance of finding suitable alternatives for accessible captchas, as the availability of audio captchas 
exposes services to significant risks.


\note{Comparison to low resource attack in w00t paper}

\note{The paper focuses only on Google ReCaptcha and only the second version of it. Unlike this paper our attack focuses on audio captchas from 8 captcha services. It utilizes 6 audio services (Google cloud, bing speech recognition, ibm bluemix, google speech api, wit ai, sphinx) to tackle the google recaptca v2. On the surface level our attack and the one described in the paper may seem similar however there are some important distinctions.} 

\note{Our attack consists of taking the entire audio file and sending it to the cloud services, and with some post processing i.e mapping consistent erroneous transcriptions checking it against the captcha service. Each solver works individually. This allows us to map the errors from each service better as distinct patterns arise per service and cloud speech recognition service. We believe this causes us to get similar rates to the one described in the w00t paper. We also observed variance in performance when each service checks the audio while set to a particular accent. We also observe that they wOOT paper does not run as extensive an evaluation as we do. (From their paper  -- After successfully running against over 450 captchas, it can defeat reCaptcha with over 85% accuracy)
}

\note{The problem statement that they approach is purely for numbers as audio captcha, whereas our attack focuses on alpha-numeric, NATO phonetic spelling, phrases which are dictionary words as well (As said before we attack 8 other services). Like our attack they also apply mappings to improve the efficiency of transcriptions received from each cloud service. They have added different categories for it whereas we lump them as one. They divide them as exact-homophone and a near homophone. They describe an exact homophone as when the word transcribed by the audio service is describing how the number sounds (for example “four” as “for” ) and a near homophone as a slightly erroneous but close enough transcription of the number (for example “six” as “sex”). }


\note{The attack method in the woot paper involves dividing the audio file into its constituent digit audio snippets and then sending those audio snippets to multiple cloud based audio services which send back a number of different valid answers and then utilizing homophone predictions to accurately decide which of those transcriptions are correct, then they assemble the digits from each service based upon a confidence score assigned as per their analysis.}

\note{Our attack method is markedly different from theirs, Their method yields comparable accuracy value as our attack does, however they do not try to use the existing features in the cloud based speech recognition i.e different accents nor do they attack other captcha services utilizing this method. Their paper additionally covers offline speech recognition based on extracting features from the audio which our paper does not consider.
}